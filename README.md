# Data Wrangling of @we_rate_dogs (twitter)

## Before you get started.
> This project is an Udacity given project that is based on
the lecture Data Wrangling that consists of gathering, assessing and 
cleaning the datasets.

> This project was done in a jupyter-notebook of an anaconda environment.

> The three datasets gathered, assessed and cleaned are:

- Archive file (A CSV file given to us for normal download)
- Image prediction file (A tsv file that has to be doenloaded 
programmatically)
- Twitter json file (A file downloaded via the twitter API 
using tweepy library which is a twitter API wrapper)

- Also the final dataset obtained after cleaning is the done:
`twitteer-archive-enhanced.csv`

### Requiremnts.txt file
> It contains the version of all libraries and dependencies of my 
local base environment where I did the project.

> Advise: If you run into library version problems, you can compare your specific
libraries and the one in the reqirements.txt.

## Datasets
> All gathered datasets including the json file from the twitter API have been gathered,
and put in the folder `Dataset`.

Note: The actual notebook still proceeds or starts with the data gathering processes.
(You can either download the datasets and proceed with assessment and cleaning or
do it from ground up)

## Others

> The main note book file is the `wrangle_act.ipynb`
> The pdfs are the reports on the wrangling and eventual
analysis performed. (wrangle_report.pdf for the wrangling process,
and act_report.pdf for the analyses and insights obtained)

